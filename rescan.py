import os
import requests
import configparser
import xml.etree.ElementTree as ET
from urllib.parse import quote
import time
from collections import defaultdict
from plexapi.server import PlexServer
import logging
import json
from datetime import datetime
import schedule
import discord
from discord import Webhook, Embed, Color
import asyncio
import aiohttp

# === CONFIG ===

config = configparser.ConfigParser()
# Docker-first config path
CONFIG_PATH = '/app/config/config.ini'
if not os.path.exists(CONFIG_PATH):
    print(f"‚ùå config.ini not found at {CONFIG_PATH}. Please ensure it's mounted in the /app/config volume.")
    exit(1)

try:
    config.read(CONFIG_PATH)

    # Validate required sections exist
    required_sections = ['plex', 'logs', 'scan', 'behaviour', 'notifications']
    missing_sections = [s for s in required_sections if not config.has_section(s)]
    if missing_sections:
        print(f"‚ùå Missing required sections in config.ini: {', '.join(missing_sections)}")
        exit(1)

    # Parse config with validation
    PLEX_URL = config.get('plex', 'server')
    TOKEN = config.get('plex', 'token')

    if not PLEX_URL or PLEX_URL == 'http://localhost:32400':
        print("‚ö†Ô∏è  Warning: Using default Plex URL. Make sure this is correct.")
    if not TOKEN or TOKEN == 'your_plex_token_here':
        print("‚ùå Plex token not configured. Please set your token in config.ini")
        exit(1)

    LOG_LEVEL = config.get('logs', 'loglevel', fallback='INFO')
    SCAN_INTERVAL = config.getint('behaviour', 'scan_interval', fallback=5)
    RUN_INTERVAL = config.getint('behaviour', 'run_interval', fallback=24)
    DISCORD_WEBHOOK_URL = config.get('notifications', 'discord_webhook_url', fallback='')
    DISCORD_AVATAR_URL = "https://raw.githubusercontent.com/secunit404/rescan/master/assets/logo.png"
    DISCORD_WEBHOOK_NAME = "Rescan"
    SYMLINK_CHECK = config.getboolean('behaviour', 'symlink_check', fallback=False)
    NOTIFICATIONS_ENABLED = config.getboolean('notifications', 'enabled', fallback=True)

    # Support both comma-separated or line-separated values
    directories_raw = config.get('scan', 'directories')
    SCAN_PATHS = [path.strip() for path in directories_raw.replace('\n', ',').split(',') if path.strip()]

    if not SCAN_PATHS:
        print("‚ùå No scan directories configured. Please set directories in config.ini")
        exit(1)

except configparser.Error as e:
    print(f"‚ùå Error parsing config.ini: {e}")
    exit(1)
except ValueError as e:
    print(f"‚ùå Invalid config value: {e}")
    exit(1)

# Media file extensions to look for
MEDIA_EXTENSIONS = {
    '.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm',
    '.m4v', '.m4p', '.m4b', '.m4r', '.3gp', '.mpg', '.mpeg',
    '.m2v', '.m2ts', '.ts', '.vob', '.iso'
}

# Global library IDs and path mappings
library_ids = {}
library_paths = {}
library_files = defaultdict(set)  # Cache of files in each library

# Initialize Plex server - will be set in main()
plex = None

def initialize_plex():
    """Initialize Plex server connection with error handling."""
    global plex
    try:
        plex = PlexServer(PLEX_URL, TOKEN)
        logger.info(f"‚úÖ Connected to Plex server: {plex.friendlyName}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Failed to connect to Plex server at {PLEX_URL}: {e}")
        return False

# ANSI escape codes for text formatting
BOLD = '\033[1m'
RESET = '\033[0m'

# Configure logging
log_handlers: list[logging.Handler] = [logging.StreamHandler()]

# Add file handler if LOG_FILE is configured
LOG_FILE = config.get('logs', 'logfile', fallback=None)
if LOG_FILE:
    try:
        log_handlers.append(logging.FileHandler(LOG_FILE))
    except (OSError, PermissionError) as e:
        print(f"Warning: Could not create log file {LOG_FILE}: {e}")

logging.basicConfig(
    level=getattr(logging, LOG_LEVEL.upper()),
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%d %b %Y | %I:%M:%S %p',
    handlers=log_handlers
)
logger = logging.getLogger(__name__)

class RunStats:
    def __init__(self):
        self.start_time = datetime.now()
        self.missing_items = defaultdict(list)
        self.errors = []
        self.warnings = []
        self.total_scanned = 0
        self.total_missing = 0
        self.broken_symlinks = 0

    def add_missing_item(self, library_name, file_path):
        self.missing_items[library_name].append(file_path)
        self.total_missing += 1

    def add_error(self, error):
        self.errors.append(error)

    def add_warning(self, warning):
        self.warnings.append(warning)

    def increment_scanned(self):
        self.total_scanned += 1

    def increment_broken_symlinks(self):
        self.broken_symlinks += 1

    def get_run_time(self):
        return datetime.now() - self.start_time

    async def send_discord_summary(self):
        if not NOTIFICATIONS_ENABLED:
            logger.info("üì¢ Notifications are disabled in config.ini")
            return
            
        if not DISCORD_WEBHOOK_URL:
            logger.warning("Discord webhook URL not configured. Skipping notification.")
            return

        try:
            # Create webhook client with aiohttp session
            async with aiohttp.ClientSession() as session:
                webhook = Webhook.from_url(DISCORD_WEBHOOK_URL, session=session)

                # Create embed
                embed = Embed(
                    title="Rescan Summary",
                    color=Color.blue(),
                    timestamp=datetime.now()
                )

                # Add overview
                embed.add_field(
                    name="üìä Overview",
                    value=f"Found **{self.total_missing}** items from **{self.total_scanned}** scanned files",
                    inline=False
                )

                # Add broken symlinks summary if any
                if self.broken_symlinks > 0:
                    embed.add_field(
                        name="‚ö†Ô∏è Issues",
                        value=f"Broken Symlinks Skipped: **{self.broken_symlinks}**",
                        inline=False
                    )

                # Add library-specific stats
                for library, items in self.missing_items.items():
                    embed.add_field(
                        name=f"üìÅ {library}",
                        value=f"Found: **{len(items)}** items",
                        inline=True
                    )

                # Add other errors and warnings if any
                if self.errors or self.warnings:
                    error_text = "\n".join([f"‚ùå {e}" for e in self.errors])
                    warning_text = "\n".join([f"‚ö†Ô∏è {w}" for w in self.warnings])
                    if error_text or warning_text:
                        embed.add_field(
                            name="‚ö†Ô∏è Other Issues",
                            value=f"{error_text}\n{warning_text}",
                            inline=False
                        )

                # Add footer
                embed.set_footer(text=f"Run Time: {self.get_run_time()}")

                # Send webhook
                await send_discord_webhook(webhook, embed)
                logger.info("‚úÖ Discord notification sent successfully")

        except discord.HTTPException as e:
            logger.error(f"Discord API error: {str(e)}")
        except Exception as e:
            logger.error(f"Failed to send Discord notification: {str(e)}")

async def send_discord_webhook(webhook, embed):
    """Send a Discord webhook message."""
    try:
        # Check if embed exceeds Discord's limits
        if len(str(embed)) > 6000:
            # Split into multiple embeds
            base_embed = Embed(
                title=embed.title,
                color=embed.color,
                timestamp=embed.timestamp
            )
            
            # Add overview field
            if embed.fields and embed.fields[0].name == "üìä Overview":
                base_embed.add_field(
                    name=embed.fields[0].name,
                    value=embed.fields[0].value,
                    inline=False
                )
            
            # Send base embed
            await webhook.send(
                embed=base_embed,
                avatar_url=DISCORD_AVATAR_URL,
                username=DISCORD_WEBHOOK_NAME,
                wait=True
            )
            
            # Create additional embeds for libraries
            current_embed = Embed(
                title="üìÅ Library Details",
                color=embed.color,
                timestamp=embed.timestamp
            )
            
            # Add library fields
            for field in embed.fields[1:]:
                if field.name.startswith("üìÅ"):
                    if len(str(current_embed)) + len(str(field)) > 6000:
                        # Send current embed and create new one
                        await webhook.send(
                            embed=current_embed,
                            avatar_url=DISCORD_AVATAR_URL,
                            username=DISCORD_WEBHOOK_NAME,
                            wait=True
                        )
                        current_embed = Embed(
                            title="üìÅ Library Details (continued)",
                            color=embed.color,
                            timestamp=embed.timestamp
                        )
                    current_embed.add_field(
                        name=field.name,
                        value=field.value,
                        inline=field.inline
                    )
            
            # Send final library embed if it has fields
            if current_embed.fields:
                await webhook.send(
                    embed=current_embed,
                    avatar_url=DISCORD_AVATAR_URL,
                    username=DISCORD_WEBHOOK_NAME,
                    wait=True
                )
            
            # Send issues in separate embed if they exist
            if embed.fields and embed.fields[-1].name == "‚ö†Ô∏è Issues":
                issues_embed = Embed(
                    title="‚ö†Ô∏è Issues",
                    color=Color.red(),
                    timestamp=embed.timestamp
                )
                issues_embed.add_field(
                    name=embed.fields[-1].name,
                    value=embed.fields[-1].value,
                    inline=False
                )
                await webhook.send(
                    embed=issues_embed,
                    avatar_url=DISCORD_AVATAR_URL,
                    username=DISCORD_WEBHOOK_NAME,
                    wait=True
                )
        else:
            # Send single embed if within limits
            await webhook.send(
                embed=embed,
                avatar_url=DISCORD_AVATAR_URL,
                username=DISCORD_WEBHOOK_NAME,
                wait=True
            )
    except discord.HTTPException as e:
        logger.error(f"Discord API error: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"Failed to send webhook: {str(e)}")
        raise

def get_library_ids():
    """Fetch library section IDs and paths dynamically from Plex."""
    global library_ids, library_paths
    if not plex:
        logger.error("Plex server not initialized")
        return {}
    for section in plex.library.sections():
        lib_type = section.type
        lib_key = section.key
        lib_title = section.title
        library_ids[lib_type] = lib_key
        
        # Get the path for this library
        for location in section.locations:
            library_paths[location] = lib_key
            logger.debug(f"Found library '{lib_title}' (ID: {lib_key}) at path: {location}")

    return library_ids

def get_library_id_for_path(file_path):
    """Get the library section ID for a given file path."""
    # Get all library sections
    url = f"{PLEX_URL}/library/sections"
    params = {'X-Plex-Token': TOKEN}
    response = requests.get(url, params=params)
    response.raise_for_status()
    root = ET.fromstring(response.content)
    
    # Find matching sections
    matching_sections = []
    for section in root.findall('Directory'):
        section_type = section.get('type')
        section_id = section.get('key')
        section_title = section.get('title')
        
        # Get all locations for this section
        for location in section.findall('Location'):
            location_path = location.get('path')
            matching_sections.append((section_id, section_type, location_path, section_title))
    
    # Find best matching section (prefer more specific matches)
    best_match = None
    best_match_length = 0
    
    for section_id, section_type, location_path, section_title in matching_sections:
        # Normalize paths for comparison
        normalized_scan_path = os.path.normpath(file_path)
        normalized_location = os.path.normpath(location_path)
        
        # Check if the file path starts with the library location
        if normalized_scan_path.startswith(normalized_location):
            # Use the longest matching path (most specific)
            if len(normalized_location) > best_match_length:
                best_match = (section_id, section_title)
                best_match_length = len(normalized_location)
    
    if best_match:
        section_id, section_title = best_match
        logger.debug(f"Found best match in section: {section_title} (id: {section_id})")
        return section_id, section_title
    
    logger.warning(f"No matching library found for path: {file_path}")
    return None, None

def cache_library_files(library_id):
    """Cache all files in a library section."""
    if library_id in library_files:
        logger.debug(f"Using cached files for library {BOLD}{library_id}{RESET}...")
        return  # Already cached

    if not plex:
        logger.error("Plex server not initialized")
        return

    try:
        section = plex.library.sectionByID(int(library_id))
        logger.info(f"üíæ Initializing cache for library {BOLD}{section.title}{RESET}...")
        cache_start = time.time()
        
        if section.type == 'show':
            # For TV shows, get all episodes
            for show in section.all():
                for episode in show.episodes():
                    for media in episode.media:
                        for part in media.parts:
                            if part.file:
                                library_files[library_id].add(part.file)
        else:
            # For movies, get all items
            for item in section.all():
                for media in item.media:
                    for part in media.parts:
                        if part.file:
                            library_files[library_id].add(part.file)
        
        cache_time = time.time() - cache_start
        logger.info(f"üíæ Cache initialized for library {BOLD}{section.title}{RESET}: {BOLD}{len(library_files[library_id])}{RESET} files in {BOLD}{cache_time:.2f}{RESET} seconds")
    except Exception as e:
        logger.error(f"Error caching library {library_id}: {str(e)}")
        # Clear the cache for this library if there was an error
        if library_id in library_files:
            del library_files[library_id]

def is_in_plex(file_path):
    """Check if a file exists in Plex by searching in the appropriate library section."""
    # Get the library ID for this path
    library_id, library_title = get_library_id_for_path(file_path)
    if not library_id:
        return False

    # Cache library files if not already cached
    cache_library_files(library_id)
    
    # Check if file exists in cached paths using exact matching
    is_found = file_path in library_files[library_id]
    if is_found:
        logger.debug(f"Found in cache: {BOLD}{file_path}{RESET}")
    return is_found

def scan_folder(library_id, folder_path):
    """Trigger a library scan for a specific folder."""
    # Ensure library_id is a string
    library_id = str(library_id)
    encoded_path = quote(folder_path)
    url = f"{PLEX_URL}/library/sections/{library_id}/refresh?path={encoded_path}&X-Plex-Token={TOKEN}"
    logger.debug(f"Scan URL: {url}")
    response = requests.get(url)
    logger.info(f"üîé Scan triggered for: {BOLD}{folder_path}{RESET}")
    logger.info(f"‚è≥ Waiting {BOLD}{SCAN_INTERVAL}{RESET} seconds before next scan")
    time.sleep(SCAN_INTERVAL)  # Wait between scans

def is_broken_symlink(file_path):
    """Check if a file is a broken symlink."""
    if not os.path.islink(file_path):
        return False
    return not os.path.exists(os.path.realpath(file_path))

def run_scan():
    """Main scan logic."""
    stats = RunStats()
    
    # Clear any existing cache at the start of a new scan
    library_files.clear()
    logger.info("Cache cleared for new scan")
    
    library_ids = get_library_ids()
    MOVIE_LIBRARY_ID = library_ids.get('movie')
    TV_LIBRARY_ID = library_ids.get('show')

    if not MOVIE_LIBRARY_ID or not TV_LIBRARY_ID:
        error_msg = "Could not find both Movie and TV Show libraries."
        logger.error(error_msg)
        stats.add_error(error_msg)
        asyncio.run(stats.send_discord_summary())
        return

    scanned_folders = set()

    for SCAN_PATH in SCAN_PATHS:
        logger.info(f"\nScanning directory: {BOLD}{SCAN_PATH}{RESET}")

        if not os.path.isdir(SCAN_PATH):
            error_msg = f"Directory not found: {SCAN_PATH}"
            logger.error(error_msg)
            stats.add_error(error_msg)
            continue

        for root, dirs, files in os.walk(SCAN_PATH):
            for file in files:
                if file.startswith('.'):
                    continue  # skip hidden/system files

                file_ext = os.path.splitext(file)[1].lower()
                if file_ext not in MEDIA_EXTENSIONS:
                    continue  # skip non-media files

                file_path = os.path.join(root, file)
                
                # Check for broken symlinks if enabled
                if SYMLINK_CHECK and is_broken_symlink(file_path):
                    warning_msg = f"‚è© Skipping broken symlink: {file_path}"
                    logger.warning(warning_msg)
                    stats.increment_broken_symlinks()
                    continue

                stats.increment_scanned()

                if not is_in_plex(file_path):
                    library_id, library_title = get_library_id_for_path(file_path)
                    if library_title:
                        stats.add_missing_item(library_title, file_path)
                        logger.info(f"üìÅ Found missing item: {BOLD}{file_path}{RESET}")
                    
                        # Determine library type and scan parent folder
                        parent_folder = os.path.dirname(file_path)
                        if parent_folder not in scanned_folders:
                            if library_id:
                                scan_folder(library_id, parent_folder)
                                scanned_folders.add(parent_folder)
                            else:
                                warning_msg = f"Could not determine library for path: {file_path}"
                                logger.warning(warning_msg)
                                stats.add_warning(warning_msg)

    # Send the final summary to Discord
    asyncio.run(stats.send_discord_summary())

def main():
    """Main function to run the scanner on a schedule."""
    logger.info("Starting Plex Missing Files Scanner")

    # Initialize Plex connection
    if not initialize_plex():
        logger.error("Failed to initialize Plex connection. Exiting.")
        exit(1)

    logger.info(f"Will run every {BOLD}{RUN_INTERVAL}{RESET} hours")

    # Run immediately on startup
    run_scan()

    # Schedule subsequent runs
    schedule.every(RUN_INTERVAL).hours.do(run_scan)

    while True:
        schedule.run_pending()
        time.sleep(60)  # Check every minute for pending tasks

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        logger.info("\nüëã Shutting down gracefully...")
        exit(0)
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}")
        exit(1)
